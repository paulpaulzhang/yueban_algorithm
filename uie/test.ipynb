{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'待办': [{'end': 10, 'probability': 0.9994872, 'start': 7, 'text': '写作业'}],\n",
      "  '时间': [{'end': 7, 'probability': 0.9997067, 'start': 0, 'text': '今天八点到九点'}]}]\n"
     ]
    }
   ],
   "source": [
    "from uie_predictor_convert import UIEPredictor\n",
    "from pprint import pprint\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "schema = ['时间', '待办'] # Define the schema for entity extraction\n",
    "ie = UIEPredictor(task_path='./checkpoint/model_best', schema=schema)\n",
    "pprint(ie('今天八点到九点写作业')) # Better print results using pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推理失败\n",
    "# 睡觉 这俩字推理失败\n",
    "# 提醒我睡觉\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained('./uie_base_pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 849, 315, 2, 28, 1598, 160, 1519, 75, 88, 32, 2], 'token_type_ids': [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 1), (1, 2), (0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (0, 0)]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(text=\"待办\", text_pair=\"上午提醒我开会\", return_offsets_mapping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 1, 226, 170, 1260, 2, 75, 321, 170, 30, 10334, 1904, 30675, 2072, 2, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('[CLS]你好啊[SEP]我很好,nice to meet you[SEP]', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[    1,     1,   226,   170,  1260,     2,    75,   321,   170,\n",
       "           30, 10334,  1904, 30675,  2072,     2,     2,  4695, 32246,\n",
       "        31319,     2]]), 'token_type_ids': array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]]), 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_plus(['[CLS]你好啊[SEP]我很好,nice to meet you[SEP]', 'sdgdfg'],padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,return_tensors=\"np\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[   1,  748,   28,  643,  180,  951,   75,  943, 1528,    2],\n",
       "       [   1,   86, 1598,  127,  180,    2,    0,    0,    0,    0],\n",
       "       [   1,  943, 1528,    2,    0,    0,    0,    0,    0,    0]]), 'token_type_ids': array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]]), 'offset_mapping': array([[[0, 0],\n",
       "        [0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3],\n",
       "        [3, 4],\n",
       "        [4, 5],\n",
       "        [5, 6],\n",
       "        [6, 7],\n",
       "        [7, 8],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3],\n",
       "        [3, 4],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [0, 1],\n",
       "        [1, 2],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]]])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_encode_plus(\n",
    "    text=['早上八点叫我吃饭', '下午三点', '吃饭'],\n",
    "    stride=2,\n",
    "    truncation=True,\n",
    "    max_length=54,\n",
    "    padding='longest',\n",
    "    add_special_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    return_tensors=\"np\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel base (Python 3.10.6) is not usable. Check the Jupyter output tab for more information. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    ":gpt 帮我生成10条常用的待办或者提醒的常用语句，并将时间和事件写出来，使用json格式输出 如{\"text\":\"下午4点去银行办理业务\",\"time\": \"下午4点\", \"todo\": \"去银行办理业务\"}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. 今天下午2点开会\n",
    "2. 明天早上9点去银行\n",
    "3. 今晚7点和朋友聚餐\n",
    "4. 下周一早上10点去医院体检\n",
    "5. 今天晚上8点去看电影\n",
    "6. 明天中午12点和客户见面\n",
    "7. 今晚9点开始写报告\n",
    "8. 明天下午3点去超市购物\n",
    "9. 下周三晚上6点参加运动会\n",
    "10. 明天早上10点开车去机场接人\n",
    "11. 今天晚上7点开始做晚饭\n",
    "12. 明天下午2点去美容院做护理\n",
    "13. 明天晚上8点和同事开会\n",
    "14. 今天下午4点去邮局寄信\n",
    "15. 明天晚上7点去游泳\n",
    "16. 下周一早上9点去开会\n",
    "17. 今晚10点开始做作业\n",
    "18. 明天晚上6点去健身房锻炼\n",
    "19. 明天下午5点去约会\n",
    "20. 今天下午3点去开车练习\n",
    "21. 明天早上11点去办理银行业务\n",
    "22. 今晚9点开始看电视剧\n",
    "23. 明天下午4点去图书馆借书\n",
    "24. 明天晚上7点去参加生日派对\n",
    "25. 下周三早上8点去开会\n",
    "26. 今天晚上6点开始打扫房间\n",
    "27. 明天下午1点去逛街购物\n",
    "28. 明天晚上8点去听音乐会\n",
    "29. 今天下午2点去做理发\n",
    "30. 明天早上10点去上课\n",
    "31. 今晚9点开始写论文\n",
    "32. 明天下午3点去做牙齿保健\n",
    "33. 明天晚上7点去和朋友打牌\n",
    "34. 下周一早上9点去开车考试\n",
    "35. 今天晚上8点开始看电影\n",
    "36. 明天下午2点去参观博物馆\n",
    "37. 明天晚上6点去参加婚礼\n",
    "38. 今天下午4点去做家务\n",
    "39. 明天早上11点去吃早餐\n",
    "40. 今晚10点开始玩游戏\n",
    "41. 明天下午5点去做瑜伽\n",
    "42. 明天晚上8点去和同事聚餐\n",
    "43. 下周三早上9点去开会\n",
    "44. 今天晚上7点开始做晚餐\n",
    "45. 明天下午4点去做推拿\n",
    "46. 明天晚上7点去和家人聚会\n",
    "47. 明天早上10点去逛菜市场\n",
    "48. 今晚9点开始看电视\n",
    "49. 明天下午3点去做美容\n",
    "50. 明天晚上6点去参加朋友婚礼\n",
    "51. 明天早上9点去上班\n",
    "52. 今天下午2点去做体检\n",
    "53. 明天晚上8点去看话剧\n",
    "54. 今天晚上6点开始做晚饭\n",
    "55. 明天下午1点去逛商场\n",
    "56. 明天晚上7点去和朋友唱歌\n",
    "57. 下周一早上10点去开车旅行\n",
    "58. 今天下午4点去做家务\n",
    "59. 明天早上11点去理财\n",
    "60. 今晚10点开始看电视剧\n",
    "61. 明天下午5点去做瑜伽\n",
    "62. 明天晚上8点去和同事聚餐\n",
    "63. 下周三早上9点去开会\n",
    "64. 今天晚上7点开始做晚餐\n",
    "65. 明天下午4点去做推拿\n",
    "66. 明天晚上7点去和家人聚会\n",
    "67. 明天早上10点去逛菜市场\n",
    "68. 今晚9点开始看电视\n",
    "69. 明天下午3点去做美容\n",
    "70. 明天晚上6点去参加朋友婚礼\n",
    "71. 明天早上9点去上班\n",
    "72. 今天下午2点去做体检\n",
    "73. 明天晚上8点去看话剧\n",
    "74. 今天晚上6点开始做晚饭\n",
    "75. 明天下午1点去逛商场\n",
    "76. 明天晚上7点去和朋友唱歌\n",
    "77. 下周一早上10点去开车旅行\n",
    "78. 今天下午4点去做家务\n",
    "79. 明天早上11点去理财\n",
    "80. 今晚10点开始看电视剧\n",
    "81. 明天下午5点去做瑜伽\n",
    "82. 明天晚上8点去和同事聚餐\n",
    "83. 下周三早上9点去开会\n",
    "84. 今天晚上7点开始做晚餐\n",
    "85. 明天下午4点去做推拿\n",
    "86. 明天晚上7点去和家人聚会\n",
    "87. 明天早上10点去逛菜市场\n",
    "88. 今晚9点开始看电视\n",
    "89. 明天下午3点去做美容\n",
    "90. 明天晚上6点去参加朋友婚礼\n",
    "91. 明天早上9点去上班\n",
    "92. 今天下午2点去做体检\n",
    "93. 明天晚上8点去看话剧\n",
    "94. 今天晚上6点开始做晚饭\n",
    "95. 明天下午1点去逛商场\n",
    "96. 明天晚上7点去和朋友唱歌\n",
    "97. 下周一早上10点去开车旅行\n",
    "98. 今天下午4点去做家务\n",
    "99. 明天早上11点去理财\n",
    "100. 今晚10点开始看电视剧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4276839268.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    :gpt 写个正则表达式匹任意数字\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    ":gpt 写个正则表达式匹任意数字\n",
    "正则表达式：\\d+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7e6fa13d970822f1c4bf0089848538e2330195bb5b11435449233f6f926edf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
